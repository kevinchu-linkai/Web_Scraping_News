{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# open urls_uncleaned.csv\n",
    "df = pd.read_csv('urls_uncleaned.csv', header=None, encoding='utf-8')\n",
    "\n",
    "# positive filtering\n",
    "df = df[df[1].str.len() >= 45]\n",
    "df = df[df[1].str.contains(\"/www.\")]\n",
    "df = df[df[1].str.contains(\"us\")]\n",
    "\n",
    "# # negative filtering\n",
    "df = df[~df[1].str.contains(\"/video/\")]\n",
    "df = df[~df[1].str.contains(\"/videos/\")]\n",
    "df = df[~df[1].str.contains(\"/showbiz/\")]\n",
    "\n",
    "\n",
    "\n",
    "df = df[~df[1].str.contains(\"/live-news/\")]\n",
    "df = df[~df[1].str.contains(\"/africa/\")]\n",
    "df = df[~df[1].str.contains(\"/asia/\")]\n",
    "df = df[~df[1].str.contains(\"/gallery/\")]\n",
    "df = df[~df[1].str.contains(\"/media/\")]\n",
    "df = df[~df[1].str.contains(\"/design/\")]\n",
    "df = df[~df[1].str.contains(\"/specials/\")]\n",
    "df = df[~df[1].str.contains(\"/weather/\")]\n",
    "df = df[~df[1].str.contains(\"/homes/\")]\n",
    "df = df[~df[1].str.contains(\"/europe/\")]\n",
    "df = df[~df[1].str.contains(\"/living/\")]\n",
    "df = df[~df[1].str.contains(\"/travel/\")]\n",
    "df = df[~df[1].str.contains(\"/health/\")]\n",
    "df = df[~df[1].str.contains(\"/interactive/\")]\n",
    "\n",
    "# sorting and duplicate removal\n",
    "df[\"length\"] = df[1].str.len()\n",
    "df.sort_values(by=\"length\", ascending=True, inplace=True)\n",
    "df.drop(columns=\"length\", inplace=True)\n",
    "\n",
    "# Drop the duplicates\n",
    "df.drop_duplicates(subset=[1], inplace=True)  # Assuming the second column has index 1\n",
    "\n",
    "# convert the first column to datetime\n",
    "df[3] = pd.to_datetime((df[0]).astype(str).str[:8], format=\"%Y%m%d\", errors='coerce')\n",
    "\n",
    "# save the cleaned dataframe to urls_cleaned.csv\n",
    "df.to_csv('urls_cleaned.csv', header=None, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'RangeIndex'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murl\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 9\u001b[0m df_weekly \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     10\u001b[0m df_weekly \u001b[38;5;241m=\u001b[39m df_weekly\u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# plot the number of urls per day\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/github-repositories/web-scrape-newswebsites/venv/lib/python3.12/site-packages/pandas/core/generic.py:9768\u001b[0m, in \u001b[0;36mNDFrame.resample\u001b[0;34m(self, rule, axis, closed, label, convention, kind, on, level, origin, offset, group_keys)\u001b[0m\n\u001b[1;32m   9765\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   9766\u001b[0m     convention \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 9768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_resampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   9769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSeries | DataFrame\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrule\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclosed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9773\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconvention\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkey\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9778\u001b[0m \u001b[43m    \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9779\u001b[0m \u001b[43m    \u001b[49m\u001b[43moffset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   9781\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github-repositories/web-scrape-newswebsites/venv/lib/python3.12/site-packages/pandas/core/resample.py:2050\u001b[0m, in \u001b[0;36mget_resampler\u001b[0;34m(obj, kind, **kwds)\u001b[0m\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2047\u001b[0m \u001b[38;5;124;03mCreate a TimeGrouper and return our resampler.\u001b[39;00m\n\u001b[1;32m   2048\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2049\u001b[0m tg \u001b[38;5;241m=\u001b[39m TimeGrouper(obj, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m-> 2050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_resampler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/github-repositories/web-scrape-newswebsites/venv/lib/python3.12/site-packages/pandas/core/resample.py:2272\u001b[0m, in \u001b[0;36mTimeGrouper._get_resampler\u001b[0;34m(self, obj, kind)\u001b[0m\n\u001b[1;32m   2263\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ax, TimedeltaIndex):\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m TimedeltaIndexResampler(\n\u001b[1;32m   2265\u001b[0m         obj,\n\u001b[1;32m   2266\u001b[0m         timegrouper\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2269\u001b[0m         gpr_index\u001b[38;5;241m=\u001b[39max,\n\u001b[1;32m   2270\u001b[0m     )\n\u001b[0;32m-> 2272\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   2273\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly valid with DatetimeIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2274\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTimedeltaIndex or PeriodIndex, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2275\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got an instance of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(ax)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2276\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: Only valid with DatetimeIndex, TimedeltaIndex or PeriodIndex, but got an instance of 'RangeIndex'"
     ]
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "import nbformat\n",
    "\n",
    "df = pd.read_csv('urls_cleaned.csv', header=None, encoding='utf-8')\n",
    "df.columns = ['id','url','status','date']\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "\n",
    "# plot the number of urls per day\n",
    "fig = px.line(\n",
    "        df.groupby('date').count(), \n",
    "        x=df.index, \n",
    "        y='url'\n",
    "    )\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
